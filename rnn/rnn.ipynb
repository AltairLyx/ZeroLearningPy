{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import math\n",
                "import random"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RNN(nn.Module):\n",
                "    def __init__(self, x_dim, hidden_dim, output_dim) -> None:\n",
                "        super().__init__()\n",
                "        self.x_dim = x_dim\n",
                "        self.hidden_dim = hidden_dim\n",
                "        self.output_dim = output_dim\n",
                "        self.w_hx = nn.Parameter(torch.randn(size=(x_dim, hidden_dim)))\n",
                "        self.b_h = nn.Parameter(torch.randn(size=(hidden_dim,)))\n",
                "        self.w_hh = nn.Parameter(torch.randn(size=(hidden_dim, hidden_dim)))\n",
                "        self.w_qh = nn.Parameter(torch.randn(size=(hidden_dim, output_dim))) \n",
                "        self.b_q = nn.Parameter(torch.randn((output_dim,)))       \n",
                "        self.hidden_state = None\n",
                "        self.hidden_state_pre = None\n",
                "\n",
                "    def init(self, batch_size):\n",
                "        self.hidden_state = torch.zeros(size=(batch_size, self.hidden_dim))\n",
                "\n",
                "    def forward(self, X):\n",
                "        self.hidden_state = torch.matmul(self.hidden_state, self.w_hh) + torch.matmul(X, self.w_hx) + self.b_h\n",
                "        self.hidden_state = torch.tanh(self.hidden_state)\n",
                "        Y = torch.matmul(self.hidden_state, self.w_qh) + self.b_q\n",
                "        Y = torch.tanh(Y)\n",
                "        return Y\n",
                "\n",
                "    def warm_up(self, X):\n",
                "        for j in range(X.shape[1]):\n",
                "            self.forward(X[:,j])\n",
                "    \n",
                "    @classmethod\n",
                "    def generate_sample(cls, amount, sequence_length, func):\n",
                "        x = []\n",
                "        for i in range(amount):\n",
                "            r = random.random() + random.random() + random.random()\n",
                "            x.append([r + 0.1 * t for t in range(sequence_length)])\n",
                "\n",
                "        y = []\n",
                "        for i in range(amount):\n",
                "            y.append([func(t) for t in x[i]])    \n",
                "\n",
                "        x = torch.Tensor(x)\n",
                "        y = torch.Tensor(y)        \n",
                "        x = x.reshape([x.shape[0], x.shape[1], 1])\n",
                "        y = y.reshape([y.shape[0], y.shape[1], 1])\n",
                "        return x, y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.autograd.set_detect_anomaly(True)\n",
                "torch.set_printoptions(profile=\"full\")\n",
                "\n",
                "def gradient_clip(net: nn.Module, theta):\n",
                "    params = [p for p in net.parameters() if p.requires_grad]\n",
                "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
                "    if norm > theta:\n",
                "        for param in params:\n",
                "            param.grad[:] *= theta / norm\n",
                "\n",
                "def train(rnn: RNN, X_data, Y_data, batch_size, train_step = 1):\n",
                "    # data shape, [batch_size, sequence_length, dim]\n",
                "    # we are trying to the 50th elememt using the first 49 elements\n",
                "    assert X_data.shape == Y_data.shape\n",
                "    assert X_data.shape[1] > 50\n",
                "    amount = X_data.shape[0]\n",
                "    optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
                "    mse = nn.MSELoss()\n",
                "    for i in range((amount + batch_size - 1) // batch_size)[1:]:\n",
                "        Y_label = Y_data[(i - 1) * batch_size : min(amount, i * batch_size)]\n",
                "        rnn.init(batch_size)\n",
                "        Y = None\n",
                "        loss = torch.zeros(())\n",
                "        for j in range(0, 0):\n",
                "            Y = rnn(Y_label[:, j])\n",
                "        for j in range(0, 49):\n",
                "            Y = rnn(Y_label[:, j])\n",
                "            loss += mse(Y, Y_label[:, j + 1])\n",
                "        optimizer.zero_grad()\n",
                "        print(loss, Y[0], Y_label[0, 49])\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        rnn.hidden_state.detach_()\n",
                "\n",
                "# Training\n",
                "rnn = RNN(1, 5, 1)\n",
                "for i in range(100):\n",
                "    amount = 100\n",
                "    sequence_length = 60\n",
                "    X_data, Y_data = RNN.generate_sample(amount, sequence_length, math.sin)\n",
                "    train(rnn, X_data, Y_data, 10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inference\n",
                "X_data, Y_data = RNN.generate_sample(1, 500, math.sin)\n",
                "y_inf = []\n",
                "for i in range(200):\n",
                "    rnn.init(1)\n",
                "    for j in range(49):\n",
                "        y = rnn(Y_data[:, i + j])\n",
                "    y_inf.append(y[0].detach().numpy()[0])\n",
                "from matplotlib import pyplot\n",
                "\n",
                "X_show = X_data[0, 50:250].numpy()\n",
                "Y_show = Y_data[0, 50:250].numpy()\n",
                "\n",
                "pyplot.scatter(X_show, Y_show, c=\"blue\")\n",
                "pyplot.scatter(X_show, y_inf, c=\"red\")\n",
                "pyplot.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import math\n",
                "import random\n",
                "\n",
                "\n",
                "def generate_sample(amount, sequence_length, hidden_out, func):\n",
                "    X = []\n",
                "    for i in range(amount):\n",
                "        r = random.random()\n",
                "        X.append([r + 0.1 * t + 0.01 * i for t in range(sequence_length)])\n",
                "\n",
                "    Y = []\n",
                "    for i in range(amount):\n",
                "        Y.append([func(t) for t in X[i]])    \n",
                "\n",
                "    X = torch.Tensor(X)\n",
                "    Y = torch.Tensor(Y)        \n",
                "    X = X.reshape([X.shape[0], X.shape[1], 1])\n",
                "    Y = Y.reshape([Y.shape[0], Y.shape[1], 1])\n",
                "    hidden = torch.zeros([1, amount, hidden_out])\n",
                "    return X, Y, hidden\n",
                "\n",
                "x, y, hidden = generate_sample(1, 1000, 5, math.sin)\n",
                "print(\"X: \", x)\n",
                "print(\"Y: \", y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(x.shape, y.shape)\n",
                "\n",
                "class RNN(nn.Module):\n",
                "    def __init__(self) -> None:\n",
                "        super().__init__()\n",
                "        self.rnn = nn.RNN(input_size=1, hidden_size=5, batch_first=True)\n",
                "        self.linear = nn.Linear(in_features=5, out_features=1, bias=True)\n",
                "\n",
                "    def forward(self, x, hidden_state):\n",
                "        y, _ = self.rnn(x, hidden_state)\n",
                "        y = self.linear(y)\n",
                "        return y\n",
                "\n",
                "rnn = RNN()\n",
                "\n",
                "print(rnn.parameters())\n",
                "\n",
                "def train():\n",
                "    optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
                "    for i in range(2000):\n",
                "        train_x, train_y, hidden = generate_sample(10, 50, 5, math.sin)\n",
                "        # print(train_x.shape, train_y.shape, hidden.shape)\n",
                "        y_hat = rnn(train_y[:, :49, :], hidden)\n",
                "        # print(y_hat.shape)\n",
                "        mse = nn.MSELoss()\n",
                "        loss = mse(train_y[:, 1:, :], y_hat)\n",
                "        print(loss)\n",
                "        rnn.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x, y, hidden = generate_sample(1, 1000, 5, math.sin)\n",
                "print(x.shape, y.shape)\n",
                "print(x[0, 100, 0], y[0, 50, 0])\n",
                "y_inference = rnn(y[0:, 0:49, :], hidden)\n",
                "print(\"y_inference shape\", y_inference.shape)\n",
                "print(\"hidden shape\", hidden_out.shape)\n",
                "print(y_inference[0:1, -1])\n",
                "y_inference = []\n",
                "for i in range(500):\n",
                "    t = rnn(y[0:, 0 + i: 49 + i, :], hidden)\n",
                "    y_inference.append(t[0, -1, 0].detach().numpy())\n",
                "\n",
                "x = x[0, 0:500, :].detach().numpy()\n",
                "y = y[0, 0:500, :].detach().numpy()\n",
                "print(\"x.shape\", x.shape)\n",
                "print(\"y inference shape\", len(y_inference))\n",
                "from matplotlib import pyplot\n",
                "pyplot.scatter(x, y)\n",
                "pyplot.scatter(x, y_inference)\n",
                "pyplot.show()\n",
                "\n",
                "\n",
                "# print(\"y_inference\", y_inference)\n",
                "# print(y_inference[0][100][0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "b84ff043d1ce40a48e7a6204d380e64e0c4bd8261b351461971bed57374200c1"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit ('venv': venv)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
